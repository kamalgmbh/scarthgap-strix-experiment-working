From 267ee1778016212049a52feb10f770ba0a246b38 Mon Sep 17 00:00:00 2001
From: Huang Rui <ray.huang@amd.com>
Date: Thu, 30 Mar 2023 18:02:45 +0800
Subject: [PATCH 34/70] xen: map hostmem to guest

---
 hw/core/machine.c             |   3 +-
 hw/display/virtio-gpu-virgl.c |   4 ++
 hw/i386/xen/xen-mapcache.c    |  17 +++++
 include/exec/memory.h         |   1 +
 include/hw/xen/xen_native.h   | 125 ++++++++++++++++++++++++++++++++++
 softmmu/physmem.c             |   8 ++-
 6 files changed, 155 insertions(+), 3 deletions(-)

diff --git a/hw/core/machine.c b/hw/core/machine.c
index 2f6ccf5623..9fc1ebf3f0 100644
--- a/hw/core/machine.c
+++ b/hw/core/machine.c
@@ -1327,7 +1327,8 @@ void machine_run_board_init(MachineState *machine, const char *mem_path, Error *
     if (machine->memdev) {
         ram_addr_t backend_size = object_property_get_uint(OBJECT(machine->memdev),
                                                            "size",  &error_abort);
-        if (backend_size != machine->ram_size) {
+
+        if (!xen_enabled() && (backend_size != machine->ram_size)) {
             error_setg(errp, "Machine memory size does not match the size of the memory backend");
             return;
         }
diff --git a/hw/display/virtio-gpu-virgl.c b/hw/display/virtio-gpu-virgl.c
index f3c45e4aa9..df9767bc33 100644
--- a/hw/display/virtio-gpu-virgl.c
+++ b/hw/display/virtio-gpu-virgl.c
@@ -666,8 +666,12 @@ static void virgl_cmd_resource_map_blob(VirtIOGPU *g,
 
     vres->region = g_new0(MemoryRegion, 1);
     object_ref(OBJECT(g));
+    /* If a name is used, g will own mr so we don't have any refcount
+     * change here or in the unmap function.
+     */
     memory_region_init_ram_ptr(vres->region, OBJECT(vres->region), "blob",
                                size, data);
+    vres->region->is_hostmem = true;
     memory_region_add_subregion(&b->hostmem, mblob.offset, vres->region);
     memory_region_set_enabled(vres->region, true);
 
diff --git a/hw/i386/xen/xen-mapcache.c b/hw/i386/xen/xen-mapcache.c
index f7d974677d..6fc3834068 100644
--- a/hw/i386/xen/xen-mapcache.c
+++ b/hw/i386/xen/xen-mapcache.c
@@ -60,6 +60,7 @@ typedef struct MapCacheEntry {
 } MapCacheEntry;
 
 typedef struct MapCacheRev {
+    hwaddr ram_addr;
     uint8_t *vaddr_req;
     hwaddr paddr_index;
     hwaddr size;
@@ -361,6 +362,7 @@ tryagain:
                     entry->paddr_index, entry->vaddr_base);
             abort();
         }
+        reventry->ram_addr = phys_addr;
         reventry->dma = dma;
         reventry->vaddr_req = mapcache->last_entry->vaddr_base + address_offset;
         reventry->paddr_index = mapcache->last_entry->paddr_index;
@@ -421,6 +423,13 @@ ram_addr_t xen_ram_addr_from_mapcache(void *ptr)
     } else {
         raddr = (reventry->paddr_index << MCACHE_BUCKET_SHIFT) +
              ((unsigned long) ptr - (unsigned long) entry->vaddr_base);
+        {
+            if (raddr != reventry->ram_addr) {
+                fprintf(stderr, "%s: raddr=0x%lx reventry->ram_addr=0x%lx\n",
+                        __func__, raddr, reventry->ram_addr);
+                raddr = reventry->ram_addr;
+            }
+        }
     }
     mapcache_unlock();
     return raddr;
@@ -466,6 +475,12 @@ static void xen_invalidate_map_cache_entry_unlocked(uint8_t *buffer)
         DPRINTF("Trying to unmap address %p that is not in the mapcache!\n", buffer);
         return;
     }
+
+    if (entry->lock == 0) {
+        fprintf(stderr, "underflow! paddr_index=0x%lx\n", paddr_index);
+        return;
+    }
+
     entry->lock--;
     if (entry->lock > 0 || pentry == NULL) {
         return;
@@ -502,9 +517,11 @@ void xen_invalidate_map_cache(void)
         if (!reventry->dma) {
             continue;
         }
+/*
         fprintf(stderr, "Locked DMA mapping while invalidating mapcache!"
                 " "HWADDR_FMT_plx" -> %p is present\n",
                 reventry->paddr_index, reventry->vaddr_req);
+*/
     }
 
     for (i = 0; i < mapcache->nr_buckets; i++) {
diff --git a/include/exec/memory.h b/include/exec/memory.h
index 15ade918ba..05b9fb3715 100644
--- a/include/exec/memory.h
+++ b/include/exec/memory.h
@@ -763,6 +763,7 @@ struct MemoryRegion {
     bool nonvolatile;
     bool rom_device;
     bool flush_coalesced_mmio;
+    bool is_hostmem;
     uint8_t dirty_log_mask;
     bool is_iommu;
     RAMBlock *ram_block;
diff --git a/include/hw/xen/xen_native.h b/include/hw/xen/xen_native.h
index 6bcc83baf9..eaf28ad158 100644
--- a/include/hw/xen/xen_native.h
+++ b/include/hw/xen/xen_native.h
@@ -21,6 +21,8 @@
 #include "hw/pci/pci_device.h"
 #include "hw/xen/trace.h"
 
+#include "exec/ramblock.h"
+
 extern xc_interface *xen_xc;
 
 /*
@@ -478,6 +480,68 @@ static inline void xen_map_memory_section(domid_t dom,
         return;
     }
 
+    if (section->mr->is_hostmem) {
+        domid_t gdom = dom;
+        domid_t hdom = 0;
+        xen_pfn_t *hpfns;
+        xen_pfn_t start_gpfn, *gpfns;
+        unsigned int nr_pfns = size >> XC_PAGE_SHIFT;
+        int i, rc, *errs;
+        void *hva = section->mr->ram_block->host + section->offset_within_region;
+        bool is_mmio = false;
+
+        hpfns = g_malloc(nr_pfns * sizeof(*hpfns));
+        gpfns = g_malloc(nr_pfns * sizeof(*gpfns));
+        errs = g_malloc(nr_pfns * sizeof(*errs));
+        if (!hpfns || !gpfns || !errs)
+            return;
+
+        start_gpfn = start_addr >> XC_PAGE_SHIFT;
+        for (i = 0; i < nr_pfns; i++)
+            gpfns[i] = start_gpfn + i;
+
+        rc = map_hva_to_gpfns(xen_fmem, hdom, gdom, nr_pfns,
+                              hva, gpfns, hpfns, 1);
+        if (rc) {
+            fprintf(stderr, "%s: map_hva_to_gpfns failed rc=%d\n", __func__, rc);
+            goto out;
+        }
+
+        /* Note: this function uses xen_add_to_physmap_batch, which can only
+         * store the number of pages to process in a uint16_t without checking
+         * if size is larger.
+         */
+        int page_done = 0;
+        for (int p = 0; p < DIV_ROUND_UP(size, (uint16_t)0xffff) && rc == 0; p++) {
+            int n = MIN(nr_pfns - page_done, (uint16_t)0xffff);
+            rc = xc_domain_add_to_physmap_batch(xen_xc, gdom, hdom,
+                                                XENMAPSPACE_gmfn_foreign,
+                                                n, &hpfns[page_done], &gpfns[page_done], &errs[page_done]);
+            for (i = 0; i < n; i++) {
+                if (errs[page_done + i]) {
+                    rc = errs[page_done + i];
+                    break;
+                }
+            }
+            page_done += n;
+        }
+
+  out:
+        fprintf(stderr, "%s: dom=%d fd=%d hva=%p gpfn=0x%lx hpfn=0x%lx size=0x%lx is_mmio=%d rc=%d\n",
+                __func__, dom, section->mr->ram_block->fd, hva, gpfns[0], hpfns[0], size, is_mmio, rc);
+
+        g_free(hpfns);
+        g_free(gpfns);
+        g_free(errs);
+
+        if (rc == 0)
+            return;
+        else
+            section->mr->is_hostmem = false;
+    }
+
+    fprintf(stderr, "Map (%s) via ioreqserver: dom=%d addr=0x%lx-0x%lx size=0x%lx\n",
+            section->mr->name, dom, start_addr, end_addr, size);
     trace_xen_map_mmio_range(ioservid, start_addr, end_addr);
     xendevicemodel_map_io_range_to_ioreq_server(xen_dmod, dom, ioservid, 1,
                                                 start_addr, end_addr);
@@ -490,11 +554,72 @@ static inline void xen_unmap_memory_section(domid_t dom,
     hwaddr start_addr = section->offset_within_address_space;
     ram_addr_t size = int128_get64(section->size);
     hwaddr end_addr = start_addr + size - 1;
+    int rc;
 
     if (use_default_ioreq_server) {
         return;
     }
 
+    if (section->mr->is_hostmem) {
+        xen_pfn_t start_gpfn = start_addr >> XC_PAGE_SHIFT;
+        unsigned int i, nr_pfns = size >> XC_PAGE_SHIFT;
+
+        for (i = 0; i < nr_pfns; i++) {
+            rc = xc_domain_remove_from_physmap(xen_xc, dom, start_gpfn + i);
+            if (rc) {
+                printf("xc_domain_remove_from_physmap failed %d/%d - rc=%d\n", i, nr_pfns, rc);
+                printf("    addr=0x%lx-0x%lx\n", start_addr, end_addr);
+                break;
+            }
+        }
+
+        rc = 0; /* Pretend everything went fine. */
+        goto out;
+
+        /* Success */
+        if (rc == 0) {
+            goto out;
+        } else {
+            xen_pfn_t *hpfns, *gpfns;
+            int *errs;
+            void *hva = section->mr->ram_block->host + section->offset_within_region;
+            domid_t hdom = 0;
+
+            hpfns = g_malloc(nr_pfns * sizeof(*hpfns));
+            gpfns = g_malloc(nr_pfns * sizeof(*gpfns));
+            errs = g_malloc(nr_pfns * sizeof(*errs));
+            if (!hpfns || !gpfns || !errs)
+                return;
+
+            for (i = 0; i < nr_pfns; i++)
+                gpfns[i] = start_gpfn + i;
+
+            rc = map_hva_to_gpfns(xen_fmem, hdom, dom, nr_pfns,
+                                  hva, gpfns, hpfns, 0);
+
+            if (rc) {
+                fprintf(stderr, "%s: map_hva_to_gpfns rc=%d\n", __func__, rc);
+                goto out;
+            }
+
+            /* Fallback. */
+            rc = xc_domain_memory_mapping(xen_xc, dom, gpfns[0], hpfns[0], nr_pfns, 0);
+            if (!rc)
+                rc = xc_domain_iomem_permission(xen_xc, dom, hpfns[0], nr_pfns, 0);
+
+            g_free(hpfns);
+            g_free(gpfns);
+            g_free(errs);
+    out:
+            fprintf(stderr, "%s: addr=0x%lx-0x%lx size=0x%lx rc=%d\n",
+                    __func__, start_addr, end_addr, size, rc);
+
+            return;
+        }
+    }
+
+    fprintf(stderr, "Unmap (%s) via ioreqserver: dom=%d addr=0x%lx-0x%lx size=0x%lx\n",
+            section->mr->name, dom, start_addr, end_addr, size);
     trace_xen_unmap_mmio_range(ioservid, start_addr, end_addr);
     xendevicemodel_unmap_io_range_from_ioreq_server(xen_dmod, dom, ioservid,
                                                     1, start_addr, end_addr);
diff --git a/softmmu/physmem.c b/softmmu/physmem.c
index 0e0182d9f2..74ee13406f 100644
--- a/softmmu/physmem.c
+++ b/softmmu/physmem.c
@@ -797,7 +797,7 @@ static RAMBlock *qemu_get_ram_block(ram_addr_t addr)
     }
 
     fprintf(stderr, "Bad ram offset %" PRIx64 "\n", (uint64_t)addr);
-    abort();
+    abort(); //FIXME
 
 found:
     /* It is safe to write mru_block outside the iothread lock.  This
@@ -1789,6 +1789,11 @@ static void ram_block_add(RAMBlock *new_block, Error **errp)
     qemu_mutex_lock_ramlist();
     new_block->offset = find_ram_offset(new_block->max_length);
 
+    if (0)
+        fprintf(stderr, "%s: host=%p mr->name=%s old_ram_size=0x%lx"
+                " new_block->offset=0x%lx new_block->max_length=0x%lx\n",
+                __func__, (new_block->host)?:0, new_block->mr->name,
+                old_ram_size, new_block->offset, new_block->max_length);
     if (!new_block->host) {
         if (xen_enabled()) {
             xen_ram_alloc(new_block->offset, new_block->max_length,
@@ -1923,7 +1928,6 @@ RAMBlock *qemu_ram_alloc_from_fd(ram_addr_t size, MemoryRegion *mr,
         return NULL;
     }
     return new_block;
-
 }
 
 
-- 
2.17.1

