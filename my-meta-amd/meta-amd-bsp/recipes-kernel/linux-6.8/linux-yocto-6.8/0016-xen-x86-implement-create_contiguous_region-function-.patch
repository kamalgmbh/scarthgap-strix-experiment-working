From 0de893f3702008ebc79bd1752bc7a922ccd1a6b7 Mon Sep 17 00:00:00 2001
From: Huang Rui <ray.huang@amd.com>
Date: Tue, 14 Feb 2023 20:50:02 +0800
Subject: [PATCH 16/49] xen/x86: implement create_contiguous_region function
 for pvh domain

Signed-off-by: Huang Rui <ray.huang@amd.com>
---
 arch/x86/include/asm/xen/page.h | 15 ++++++
 arch/x86/xen/enlighten_pvh.c    | 83 +++++++++++++++++++++++++++++++++
 drivers/xen/phy-dma-ops.c       |  4 +-
 include/xen/phy-dma-ops.h       |  1 +
 4 files changed, 101 insertions(+), 2 deletions(-)

diff --git a/arch/x86/include/asm/xen/page.h b/arch/x86/include/asm/xen/page.h
index 85e63d58c074..5e33fcb0a28f 100644
--- a/arch/x86/include/asm/xen/page.h
+++ b/arch/x86/include/asm/xen/page.h
@@ -61,6 +61,21 @@ extern bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn);
 extern unsigned long __init set_phys_range_identity(unsigned long pfn_s,
 						    unsigned long pfn_e);
 
+#ifdef CONFIG_XEN_PVH
+extern int xen_pvh_create_contiguous_region(phys_addr_t pstart,
+					    unsigned int order,
+					    unsigned int address_bits,
+					    dma_addr_t *dma_handle);
+#else
+static inline int
+xen_pvh_create_contiguous_region(phys_addr_t pstart, unsigned int order,
+				 unsigned int address_bits,
+				 dma_addr_t *dma_handle)
+{
+	return 0;
+}
+#endif
+
 #ifdef CONFIG_XEN_PV
 extern int set_foreign_p2m_mapping(struct gnttab_map_grant_ref *map_ops,
 				   struct gnttab_map_grant_ref *kmap_ops,
diff --git a/arch/x86/xen/enlighten_pvh.c b/arch/x86/xen/enlighten_pvh.c
index ada3868c02c2..3fe9301f3899 100644
--- a/arch/x86/xen/enlighten_pvh.c
+++ b/arch/x86/xen/enlighten_pvh.c
@@ -11,6 +11,7 @@
 #include <xen/xen.h>
 #include <asm/xen/interface.h>
 #include <asm/xen/hypercall.h>
+#include <asm/xen/page.h>
 
 #include <xen/interface/memory.h>
 
@@ -25,6 +26,10 @@
 bool __ro_after_init xen_pvh;
 EXPORT_SYMBOL_GPL(xen_pvh);
 
+#define MAX_CONTIG_ORDER 9 /* 2MB */
+static unsigned long discontig_frames[1<<MAX_CONTIG_ORDER];
+static DEFINE_SPINLOCK(xen_reservation_lock);
+
 void __init xen_pvh_init(struct boot_params *boot_params)
 {
 	u32 msr;
@@ -72,3 +77,81 @@ void __init mem_map_via_hcall(struct boot_params *boot_params_p)
 	}
 	boot_params_p->e820_entries = memmap.nr_entries;
 }
+
+static int xen_pvh_exchange_memory(unsigned long extents_in, unsigned int order_in,
+			       unsigned long *pfns_in,
+			       unsigned long extents_out,
+			       unsigned int order_out,
+			       unsigned long *mfns_out,
+			       unsigned int address_bits)
+{
+	long rc;
+	int success;
+
+	struct xen_memory_exchange exchange = {
+		.in = {
+			.nr_extents   = extents_in,
+			.extent_order = order_in,
+			.extent_start = pfns_in,
+			.domid        = DOMID_SELF
+		},
+		.out = {
+			.nr_extents   = extents_out,
+			.extent_order = order_out,
+			.extent_start = mfns_out,
+			.address_bits = address_bits,
+			.domid        = DOMID_SELF
+		}
+	};
+
+	BUG_ON(extents_in << order_in != extents_out << order_out);
+
+	rc = HYPERVISOR_memory_op(XENMEM_exchange, &exchange);
+	success = (exchange.nr_exchanged == extents_in);
+
+	BUG_ON(!success && ((exchange.nr_exchanged != 0) || (rc == 0)));
+	BUG_ON(success && (rc != 0));
+
+	return success;
+}
+
+int xen_pvh_create_contiguous_region(phys_addr_t pstart, unsigned int order,
+				     unsigned int address_bits,
+				     dma_addr_t *dma_handle)
+{
+	unsigned long *in_frames = discontig_frames, out_frame;
+	unsigned long  flags;
+	int            success;
+	unsigned long vstart = (unsigned long)phys_to_virt(pstart);
+
+	/*
+	 * Currently an auto-translated guest will not perform I/O, nor will
+	 * it require PAE page directories below 4GB. Therefore any calls to
+	 * this function are redundant and can be ignored.
+	 */
+
+	if (unlikely(order > MAX_CONTIG_ORDER))
+		return -ENOMEM;
+
+	if (in_frames) {
+		unsigned long vaddr = vstart;
+		int i;
+		for (i = 0; i < (1UL<<order); i++, vaddr += PAGE_SIZE)
+			in_frames[i] = virt_to_pfn(vaddr);
+	}
+
+	memset((void *) vstart, 0, PAGE_SIZE << order);
+
+	spin_lock_irqsave(&xen_reservation_lock, flags);
+
+	/* Get a new contiguous memory extent. */
+	out_frame = virt_to_pfn(vstart);
+	success = xen_pvh_exchange_memory(1UL << order, 0, in_frames,
+				      1, order, &out_frame,
+				      address_bits);
+
+	spin_unlock_irqrestore(&xen_reservation_lock, flags);
+
+	*dma_handle = out_frame << PAGE_SHIFT;
+	return success ? 0 : -ENOMEM;
+}
diff --git a/drivers/xen/phy-dma-ops.c b/drivers/xen/phy-dma-ops.c
index 84b345942246..b6427b491158 100644
--- a/drivers/xen/phy-dma-ops.c
+++ b/drivers/xen/phy-dma-ops.c
@@ -34,8 +34,8 @@ xen_phy_alloc_coherent(struct device *dev, size_t size,
 
 	*dma_handle = xen_phys_to_dma(dev, phys);
 
-	if (xen_create_contiguous_region(phys, order, fls64(dma_mask),
-			dma_handle) != 0)
+	if (xen_pvh_create_contiguous_region(phys, order, fls64(dma_mask),
+					     dma_handle) != 0)
 		goto out_free_pages;
 	SetPageXenRemapped(virt_to_page(ret));
 
diff --git a/include/xen/phy-dma-ops.h b/include/xen/phy-dma-ops.h
index 603ee61f899e..d1c5e7f61ad7 100644
--- a/include/xen/phy-dma-ops.h
+++ b/include/xen/phy-dma-ops.h
@@ -4,6 +4,7 @@
 
 #include <linux/dma-direct.h>
 #include <linux/dma-map-ops.h>
+#include <asm/xen/page.h>
 
 extern const struct dma_map_ops xen_phy_dma_ops;
 
-- 
2.17.1

